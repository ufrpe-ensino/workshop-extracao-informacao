{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "name": "01-PLN-spaCy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ufrpe-ensino/workshop-extracao-informacao/blob/main/notebooks/02-Demo-spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CrK2e4Skshf"
      },
      "source": [
        "# spaCy\n",
        "\n",
        "spaCy é uma biblioteca para PLN que se tornado bastante popular nos últimos anos. Ela é mais recente que o NLTK, projetada especificamente para i) trabalhar em problemas maiores e ii) ocultar detalhes irrelevantes para o  usuário. Vamos nos concentrar nos principais recursos:\n",
        "\n",
        "[Carregando modelos pré-treinados](#loading)<br>\n",
        "\n",
        "[Tokenization](#tokenization)<br>\n",
        "\n",
        "[Lemmatization](#lemma)<br>\n",
        "\n",
        "[Named entity recognition (NER)](#ner)<br>\n",
        "\n",
        "[Visualizando NER](#visualize-ner)<br>\n",
        "\n",
        "[Word vectors e Similaridades](#vectors)<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rndqN2HxleIw"
      },
      "source": [
        "# Instalação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U_RUJ4ZlhGC"
      },
      "source": [
        "!pip install spacy\n",
        "!spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09htAjC3kshg"
      },
      "source": [
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUa76gWJkshk"
      },
      "source": [
        "## Loading spaCy models <a id='loading'></a>\n",
        "\n",
        "O spaCy disponibiliza uma série de [modelos](https://spacy.io/usage/models) pré-treinados, que devem ser baixados e podem funcionar em problemas mais genéricos. spaCy possui modelos diferentes para diferentes idiomas, inclusive em português. \n",
        "\n",
        "Para fazer uso dos modelos, primeiro os carregamos no spaCy com `nlp = spacy.load ('pt_core_news_sm')`, que armazena o modelo em uma variável chamada nlp para nós. O `'pt_core_news_sm'` significa o nome do modelo de linguagem que se quer carregar. O modelo carregado aqui, corresponde a um modelo de CNN treinado em um subconjunto da base WikiNER.\n",
        "\n",
        "Além do `pt_core_news_sm`, o spacy possui o `pt_core_news_md` e o `pt_core_news_lg`. Detalhes das bases utilizadas e acurácia de cada modelo podem ser vistos [aqui](https://spacy.io/models/pt). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYc5VJ3Ikshl"
      },
      "source": [
        "nlp = spacy.load('pt_core_news_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PheBKMAgksho"
      },
      "source": [
        "O modelo agora pode ser acessado através da variável `nlp`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRPytSihn9Ik"
      },
      "source": [
        "doc = nlp(\"Eu gostaria que as aboboras viessem com mais sementes.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXiXd4ukshu"
      },
      "source": [
        "## Tokenization <a id='tokenization'></a>\n",
        "\n",
        "A tokenização no spaCy é bem simples de ser utilizada com os modelos pré-treinados. Quando iteramos sobre um objeto `Doc`, spaCy assume que queremos iterar sobre os tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "uERG0k6Ukshv"
      },
      "source": [
        "for token in doc:\n",
        "    print(token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ndAAQ6lksh7"
      },
      "source": [
        "# quantidade de tokens\n",
        "len(doc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXZzON8rkshy"
      },
      "source": [
        "Cada `token` em `doc` é uma instância da classe `Token`. Este objeto armazena uma série de informações relevantes. como a representação em string do token (`.text`) o índice (`.idx`), ou ainda aspectos linguísticos como `.is_stop`,  `.is_space`, `.lemma_`  e `.pos_`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCKCNrc2kshy"
      },
      "source": [
        "for token in doc:\n",
        "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\t{7}\".format(\n",
        "        token.text,\n",
        "        token.idx,\n",
        "        token.lemma_,\n",
        "        token.is_stop,\n",
        "        token.is_punct,\n",
        "        token.is_space,\n",
        "        token.pos_,\n",
        "        token.dep_,\n",
        "    ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0llhdANksh-"
      },
      "source": [
        "### Exercício\n",
        "\n",
        "Verifique a quantidade de tokens considerados stopwords e pontuação do texto abaixo. Imprima uma versão do texto removendo este tipo de tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Cvtyplksh-"
      },
      "source": [
        "review = \"\"\"A mineração de textos, também conhecida como mineração de dados textuais, é o \n",
        "processo de transformar texto não estruturado em um formato estruturado para \n",
        "identificar padrões significativos e novos insights. Ao aplicar técnicas analíticas \n",
        "avançadas, como Naïve Bayes, Support Vector Machines (SVM) e \n",
        "outros algoritmos de aprendizado profundo, as empresas podem explorar e \n",
        "descobrir relacionamentos ocultos em seus dados não estruturados.\"\"\"\n",
        "\n",
        "# sua resposta\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkNV8lO_qHpp"
      },
      "source": [
        "# Detecção de sentenças\n",
        "\n",
        "As sentenças detectadas pelo modelo ficam armazenadas no atributo `.sents` do objeto `Doc`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZf4oy_UqKva"
      },
      "source": [
        "doc = nlp(\"Eu estarei em Recife próxima semana. Será que levo roupa para frio?\")\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBlENetrrEX0"
      },
      "source": [
        "### Exercício\n",
        "\n",
        "1. Quantas sentenças existem no texto armazenado na variável `review`?\n",
        "\n",
        "2. Quais são essas sentencas?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0jZIC-TqY8r"
      },
      "source": [
        "# sua resposta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0RoWaxJksiC"
      },
      "source": [
        "## POS tagging\n",
        "\n",
        "Como vimos acima, ao submeter uma string ao modelo, o spacy aplica todo o pipeline de PLN ao texto, incluindo o processo de POS Tagging:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeV9D0KHksiC"
      },
      "source": [
        "doc = nlp(\"Eu estarei em Recife próxima semana. Será que levo roupa para frio?\")\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joSrl8nMksiE"
      },
      "source": [
        "Esses rótulos podem ser um pouco difíceis de interpretar... O que significa `PROPN`? e `ADP`? Use a função `explain` para obter as respostas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTcRmTMbksiF"
      },
      "source": [
        "print(spacy.explain('PROPN'))\n",
        "print(spacy.explain('ADP'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfEU0kS9ksiH"
      },
      "source": [
        "Observe que o texto (label) é sempre armazenado em um atributo com `_` no fim, pois o spaCy armazena internamente tudo na forma de hashes, para tornar o código mais eficiente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dNcZc6jksiI"
      },
      "source": [
        "for token in doc[:10]:\n",
        "    print(token.text, token.pos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-Y2TpLyksiL"
      },
      "source": [
        "### Exercício\n",
        "\n",
        "Retorne a lista de todas as POS Tags da variável `review` como uma lista de tuplas (word, pos) para cada token no texto. Quais as tags mais frequentes?\n",
        "\n",
        "Dica: você pode utilizar um `pandas.DataFrame` para facilitar as contagens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRlH28-wksiL"
      },
      "source": [
        "# sua resposta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlLNgH7GksiN"
      },
      "source": [
        "## Lemmatization <a id='lemma'></a>\n",
        "\n",
        "O spaCy não disponibiliza muitos detalhes de escolha de algoritmos para Lemmatization, o que funciona bem para a maioria dos casos, diferentemente do NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZkVi_sMksiO"
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.lemma_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HqUBmnnksiR"
      },
      "source": [
        "# Named entity recognition (NER) <a id='ner'></a>\n",
        "\n",
        "Named entity recognition (NER) é uma das principais tarefas em projetos de recuperação e extração de informação em textos. Muitas tarefas se iniciam a partir da detecção de entidades nomeadas, como a extração de relações por exemplo. \n",
        "\n",
        "Em NER, as diferentes entidades nomeadas extraídas são agrupadas por tipo. Por exemplo, \"pessoa\", \"organização\", \"local\", \"país\" etc. No spaCy, existem muitos [tipos diferentes](https://spacy.io/api/annotation#named-entities) de entidades nomeadas que ele pode extrair com modelos pré-treinados.\n",
        "\n",
        "As entidades nomeadas no spaCy estão disponíveis como propriedade `ents` de um` Doc`. O `.label_` nos diz o tipo de entidade nomeada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIQD7vOTksiS"
      },
      "source": [
        "doc = nlp(\"Eu estarei em Recife próxima semana. Será que levo roupa para frio?\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text,ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFMZNuh-ksiV"
      },
      "source": [
        "doc = nlp(\"Geraldo Júlio é o prefeito de Recife.\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text,ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X05yeFFoDiVE"
      },
      "source": [
        "#explain também funciona para entidades\n",
        "spacy.explain('LOC')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNAqQh_oksiX"
      },
      "source": [
        "### Exercício 1\n",
        "\n",
        "Extraia todas as entidades nomeadas da variável `review`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOR6zb-YksiY"
      },
      "source": [
        "# sua resposta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq3jc_2p1avB"
      },
      "source": [
        "### Exercício 2\n",
        "Utilizar a lib do python `wikipedia`, para baixar o conteúdo da página referente ao presidente Bolsonaro no wikipedia em português, e analise quais as entidades presentes nas 10 primeiras sentenças do texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP_uLoVJksia"
      },
      "source": [
        "!pip install wikipedia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErHz8BJ-ksic"
      },
      "source": [
        "import wikipedia\n",
        "wikipedia.set_lang(\"pt\")\n",
        "p = wikipedia.page(\"Jair Bolsonaro\")\n",
        "\n",
        "print(p.url)\n",
        "print(p.title)\n",
        "\n",
        "content = p.content "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdZ_Bg9q3Hi6"
      },
      "source": [
        "# sua resposta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43ZXWVoAksie"
      },
      "source": [
        "# Visualização NER <a id='visualize-ner'></a>\n",
        "\n",
        "O displaCy é uma extensão do spaCy para visualização do processo de PLN. \n",
        "\n",
        "Após importar a lib `displacy`, podemos usar o método `render` sobre o `doc` criado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGCp3Pzfksif"
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orXlFlfjksii"
      },
      "source": [
        "doc = nlp(review)\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GOU_UyY4Srt"
      },
      "source": [
        "### Exercício\n",
        "\n",
        "Utilize o `displacy` para visualizar as entidades encontradas em algumas das sentenças do conteúdo da página do wikipedia analisada no exercício anterior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJhvxC_04kUE"
      },
      "source": [
        "# sua resposta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyBBECKoksik"
      },
      "source": [
        "## Parsing de Dependencia\n",
        "\n",
        "A análise de dependência refere-se a desenhar os relacionamentos entre palavras individuais em uma frase. Assim como o NER, esse é um tópico bem importante em PLN. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SVmTfMFksil"
      },
      "source": [
        "for token in doc[:18]:\n",
        "    print(token.text, token.dep_, token.head)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpimXdJDksio"
      },
      "source": [
        "Utilizando o `displacy`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwKtQQbUksip"
      },
      "source": [
        "displacy.render(doc, style='dep', jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cld4BFg_54E8"
      },
      "source": [
        "# modificando a visualização\n",
        "displacy.render(doc, style='dep', jupyter=True, options={\"compact\": True})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gN6wn9tnksir"
      },
      "source": [
        "### Exercício\n",
        "\n",
        "Crie uma lista para cada tipo de entidade no texto da wikipedia analisado, ou seja: \n",
        "- texto (string)\n",
        "- pos\n",
        "- lemma\n",
        "- se é uma stopword (`.is_stop`)\n",
        "- se é pontuação (`.is_punct`)\n",
        "- se é um número (`.like_num`)\n",
        "- a relação de dependência (`.dep_`)\n",
        "\n",
        "Utilize as listas criadas para criar um `pandas.DataFrame`, e analise a distribuição das categorias registradas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65kvgT1eksir"
      },
      "source": [
        "doc = nlp(content)\n",
        "tokens = [token.text for token in doc]\n",
        "\n",
        "# resposta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRm7I70qksi5"
      },
      "source": [
        "## Word vectors e similaridade <a id='vectors'></a>\n",
        "\n",
        "Os modelos do spaCy em sua versão reduzida (`sm`), não incluem word vectors completos, de modo que é possível obter uma aproximação dessas distâncias. Caso se queira utilizar algo mais preciso, é recomendado utilizar os modelos `lg` (large) ou ainda carregar outros dicionários de vetores, como o word2vec, fastText, etc. O `gensim` é uma biblioteca que auxilia o uso de tais dicionários."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs8k1uYmksi5"
      },
      "source": [
        "w1 = nlp('gato')\n",
        "w2 = nlp('cachorro')\n",
        "w3 = nlp('presidente')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXqB_oMhksi7"
      },
      "source": [
        "w1.similarity(w2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6jAu79-8FyW"
      },
      "source": [
        "w2.similarity(w3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRPK-mvfksi9"
      },
      "source": [
        "Similaridade entre textos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi_9TrHZksi-"
      },
      "source": [
        "doc_review = nlp(review)\n",
        "doc_wiki   = nlp(content)\n",
        "\n",
        "doc_review.similarity(doc_wiki)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RW6KN4F7oAYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}